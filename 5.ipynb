{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Design an MLP model for multiclass classification for MNIST dataset under the condition that the number of parameters in your NN should be less than  1𝑀 . Then, train it with MNIST dataset by using the minibatch SGD under the condition that batch size is a power of 2 less than 1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-epoch/total 50, loss: 0.4479\n",
      "1-epoch/total 50, loss: 0.2593\n",
      "2-epoch/total 50, loss: 0.1000\n",
      "3-epoch/total 50, loss: 0.0913\n",
      "4-epoch/total 50, loss: 0.0452\n",
      "5-epoch/total 50, loss: 0.0470\n",
      "6-epoch/total 50, loss: 0.0323\n",
      "7-epoch/total 50, loss: 0.0325\n",
      "8-epoch/total 50, loss: 0.0531\n",
      "9-epoch/total 50, loss: 0.0173\n",
      "10-epoch/total 50, loss: 0.0963\n",
      "11-epoch/total 50, loss: 0.0295\n",
      "12-epoch/total 50, loss: 0.0097\n",
      "13-epoch/total 50, loss: 0.0544\n",
      "14-epoch/total 50, loss: 0.0088\n",
      "15-epoch/total 50, loss: 0.0043\n",
      "16-epoch/total 50, loss: 0.0042\n",
      "17-epoch/total 50, loss: 0.0101\n",
      "18-epoch/total 50, loss: 0.0026\n",
      "19-epoch/total 50, loss: 0.0046\n",
      "20-epoch/total 50, loss: 0.0022\n",
      "21-epoch/total 50, loss: 0.0024\n",
      "22-epoch/total 50, loss: 0.0018\n",
      "23-epoch/total 50, loss: 0.0011\n",
      "24-epoch/total 50, loss: 0.0012\n",
      "25-epoch/total 50, loss: 0.0010\n",
      "26-epoch/total 50, loss: 0.0008\n",
      "27-epoch/total 50, loss: 0.0015\n",
      "28-epoch/total 50, loss: 0.0004\n",
      "29-epoch/total 50, loss: 0.0006\n",
      "30-epoch/total 50, loss: 0.0007\n",
      "31-epoch/total 50, loss: 0.0002\n",
      "32-epoch/total 50, loss: 0.0013\n",
      "33-epoch/total 50, loss: 0.0012\n",
      "34-epoch/total 50, loss: 0.0005\n",
      "35-epoch/total 50, loss: 0.0002\n",
      "36-epoch/total 50, loss: 0.0004\n",
      "37-epoch/total 50, loss: 0.0008\n",
      "38-epoch/total 50, loss: 0.0004\n",
      "39-epoch/total 50, loss: 0.0001\n",
      "40-epoch/total 50, loss: 0.0009\n",
      "41-epoch/total 50, loss: 0.0004\n",
      "42-epoch/total 50, loss: 0.0002\n",
      "43-epoch/total 50, loss: 0.0004\n",
      "44-epoch/total 50, loss: 0.0001\n",
      "45-epoch/total 50, loss: 0.0002\n",
      "46-epoch/total 50, loss: 0.0001\n",
      "47-epoch/total 50, loss: 0.0002\n",
      "48-epoch/total 50, loss: 0.0004\n",
      "49-epoch/total 50, loss: 0.0003\n",
      "Training Time: 248.08\n",
      "Test for train_dataset: correctly matched/total: 59961/60000 accuracy: 99.94%\n",
      "\n",
      "Test for test_dataset: correctly matched/total: 9778/10000 accuracy: 97.78%\n",
      "\n",
      "Number of Parameters:  932362\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "### dataset for training parameters\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "### dataset for testing the accuracy of the trained parameters\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "(1) output shape of model: output is 10 instead of 1\n",
    "(2) Sigmoid --> Softmax\n",
    "(3) BCELoss --> CrossEntropyLoss\n",
    "'''\n",
    "\n",
    "'''\n",
    "Using GPU\n",
    "'''\n",
    "import torch\n",
    "import torch.optim as optim # See https://pytorch.org/docs/stable/optim.html\n",
    "from utils import *\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "'''\n",
    "Define Model\n",
    "'''\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "class MLP(nn.Module) :\n",
    "    def __init__(self, in_dim, out_dim, inter_dim1=512, inter_dim2=512, inter_dim3=512) :\n",
    "        super().__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.linear1 = nn.Linear(in_dim, inter_dim1, bias=True)\n",
    "        self.act1 = nn.ReLU()        \n",
    "        self.linear2 = nn.Linear(inter_dim1, inter_dim2, bias=True)                \n",
    "        self.act2 = nn.ReLU()        \n",
    "        self.linear3 = nn.Linear(inter_dim2, inter_dim3, bias=True)  \n",
    "        self.act3 = nn.ReLU()        \n",
    "        self.linear4 = nn.Linear(inter_dim3, out_dim, bias=True)  \n",
    "        \n",
    "    def forward(self, x) :\n",
    "        z = self.linear1(x)\n",
    "        z = self.act1(z)\n",
    "        z = self.linear2(z)\n",
    "        z = self.act2(z)\n",
    "        z = self.linear3(z)  \n",
    "        z = self.act3(z)   \n",
    "        z = self.linear4(z)\n",
    "        return z\n",
    "\n",
    "'''\n",
    "Choose loss function\n",
    "'''\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "loss = torch.nn.CrossEntropyLoss() # (2) Change to CrossEntropyLoss\n",
    "\n",
    "\n",
    "''' Define model and optimizer'''\n",
    "MLP_model = MLP(28*28,10).to(device) # (4) change input/output shape\n",
    "# Reverse mode automatic differentiation\n",
    "OPTIMIZER = optim.SGD(MLP_model.parameters(),  lr=0.1)\n",
    "\n",
    "'''\n",
    "DataLoader is used to apply minibatch SGD\n",
    "'''\n",
    "batch_size = 128\n",
    "image_size = 28*28\n",
    "# https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "num_epoch = 50\n",
    "for epoch in range(num_epoch):\n",
    "    MLP_model.to(device)\n",
    "    for image,label in train_loader :\n",
    "\n",
    "        # Forward process\n",
    "        hat_y = MLP_model(image.to(device).view(-1, 28*28)).to(device)\n",
    "        cost = loss(hat_y, label.to(device))\n",
    "\n",
    "        # Wipe up gradient in the previous step\n",
    "        OPTIMIZER.zero_grad() \n",
    "\n",
    "        # Computes the gradient of current tensor w.r.t. graph leaves.\n",
    "        cost.backward() \n",
    "\n",
    "        # Updates the parameters\n",
    "        OPTIMIZER.step()\n",
    "    \n",
    "    print(\"{}-epoch/total {}, loss: {:.4f}\".format(epoch, num_epoch, cost))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Training Time: {:.2f}\".format(end-start))\n",
    "\n",
    "\n",
    "\n",
    "MLP_model.to(\"cpu\")\n",
    "''' Test for train_dataset '''\n",
    "count = 0\n",
    "for i in range(len(train_dataset.targets)):\n",
    "    image = train_dataset.data[i]\n",
    "    label = train_dataset.targets[i]    \n",
    "\n",
    "    prediction = torch.argmax(MLP_model(image.float().to(\"cpu\").view(-1, 28*28)))\n",
    "\n",
    "    if prediction == label: \n",
    "        count += 1\n",
    "        \n",
    "print('Test for train_dataset: correctly matched/total: {}/{} accuracy: {:.2f}%\\n'.format(count, train_dataset.targets.size()[0], count/train_dataset.targets.size()[0] * 100. ) )    \n",
    "\n",
    "''' Test for test_dataset '''\n",
    "count = 0\n",
    "wrong_answer = []\n",
    "for i in range(len(test_dataset.targets)):\n",
    "    image = test_dataset.data[i]\n",
    "    label = test_dataset.targets[i]   \n",
    "    \n",
    "    prediction = torch.argmax(MLP_model(image.float().to(\"cpu\").view(-1, 28*28)))\n",
    "    if prediction == label: \n",
    "        count += 1\n",
    "    else:\n",
    "        wrong_answer += [i]   \n",
    "        \n",
    "print('Test for test_dataset: correctly matched/total: {}/{} accuracy: {:.2f}%\\n'.format(count, test_dataset.targets.size()[0], count/test_dataset.targets.size()[0] * 100. ) )    \n",
    "\n",
    "total_params = sum(p.numel() for p in MLP_model.parameters())\n",
    "print(\"Number of Parameters: \", total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Test Code ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for test_dataset: correctly matched/total: 9807/10000 accuracy: 98.07%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' Test for test_dataset '''\n",
    "count = 0\n",
    "wrong_answer = []\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "for image,label in test_loader :\n",
    "    label = label\n",
    "    prediction = torch.argmax(MLP_model(image.view(len(image),image_size)),dim=1)\n",
    "    count += (prediction == label).sum()\n",
    "    \n",
    "#     else:\n",
    "#         wrong_answer += [i]   \n",
    "        \n",
    "print('Test for test_dataset: correctly matched/total: {}/{} accuracy: {:.2f}%\\n'.format(count, len(test_dataset.targets), count/len(test_dataset.targets) * 100. ) )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Review ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layer 수를 4개 미만으로 내리니 정확도 미묘하게 내려감.\n",
    "### batch_size를 128 위로 올리니 정확도 내려감.\n",
    "### (batch_size를 올린 만큼 epoch 수를 올려야 하지만 학습 시간이 오래걸려 test 불가)\n",
    "### batch = 128, epoch = 50으로 마무리\n",
    "### inter_dim 512이상은 Parameter 1M 제한을 넘어감.\n",
    "### inter_dim 512미만은 정확도 내려감."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
